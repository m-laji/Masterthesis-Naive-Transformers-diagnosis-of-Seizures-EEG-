{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 11:21:45.431885: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#Master_Thesis for Michel Laji 2024\n",
    "#Creating a EEG classifying naive transformer model using the dataset from kaggel (https://www.kaggle.com/datasets/harunshimanto/epileptic-seizure-recognition/code)\n",
    "\n",
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8050, 178, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_data = pd.read_csv(\"train_eeg.csv\")\n",
    "x_train = train_data.iloc[:, :-1].values  # Features: all columns except the last\n",
    "y_train = train_data.iloc[:, -1].values   # Labels: the last column\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(\"test_eeg.csv\")\n",
    "x_test = test_data.iloc[:, :-1].values  # Features\n",
    "y_test = test_data.iloc[:, -1].values   # Labels\n",
    "\n",
    "# Load validation data\n",
    "val_data = pd.read_csv(\"validation_eeg.csv\")\n",
    "x_val = val_data.iloc[:, :-1].values  # Features\n",
    "y_val = val_data.iloc[:, -1].values   # Labels\n",
    "\n",
    "# Reshape features for a model expecting 3D inputs, e.g., (samples, timesteps, features)\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "\n",
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the encoder and Fedd Forward part of the transformer\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "    \n",
    "    # Feed Forward part of the transformer\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\", kernel_regularizer=l1_reg)(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1, padding='same', kernel_regularizer=l1_reg)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return (x + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\", kernel_regularizer=l1_reg)(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", kernel_regularizer=l1_reg)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 3\n",
    "batch_size = 10\n",
    "learning_rate = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 11:21:50.645673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31075 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "2024-03-28 11:21:50.646293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31075 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 178, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 178, 1)      7169        ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 178, 1)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 178, 1)      2           ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 178, 1)      0           ['layer_normalization[0][0]',    \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 178, 4)       8           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 178, 4)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 178, 1)       5           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 178, 1)      2           ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 178, 1)      0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 178, 1)      7169        ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 178, 1)       0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 178, 1)      2           ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 178, 1)      0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 178, 4)       8           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 178, 4)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 178, 1)       5           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 178, 1)      2           ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 178, 1)      0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 178, 1)      7169        ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 178, 1)       0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 178, 1)      2           ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 178, 1)      0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 178, 4)       8           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 178, 4)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 178, 1)       5           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 178, 1)      2           ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 178, 1)      0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 178, 1)      7169        ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 178, 1)       0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 178, 1)      2           ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 178, 1)      0           ['layer_normalization_6[0][0]',  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 178, 4)       8           ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 178, 4)       0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 178, 1)       5           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 178, 1)      2           ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 178, 1)      0           ['layer_normalization_7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 178)         0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          22912       ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,785\n",
      "Trainable params: 51,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 11:21:57.093695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2024-03-28 11:21:57.630685: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14afb4c4cda0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-28 11:21:57.630708: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-03-28 11:21:57.630713: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-03-28 11:21:57.634788: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-28 11:21:57.722776: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805/805 [==============================] - 18s 9ms/step - loss: 68.8969 - accuracy: 0.4745 - val_loss: 40.5502 - val_accuracy: 0.3939\n",
      "Epoch 2/3\n",
      "805/805 [==============================] - 7s 9ms/step - loss: 42.5919 - accuracy: 0.4713 - val_loss: 36.9162 - val_accuracy: 0.4478\n",
      "Epoch 3/3\n",
      "805/805 [==============================] - 7s 9ms/step - loss: 38.3374 - accuracy: 0.5266 - val_loss: 33.1476 - val_accuracy: 0.5096\n",
      "Epoch 3/3, Training Loss: 38.337371826171875\n",
      "Epoch 3/3, Validation Loss: 33.14757537841797\n"
     ]
    }
   ],
   "source": [
    "#Define the L2 Regularization\n",
    "lambda_l2 =0.01\n",
    "l1_reg = regularizers.l2(lambda_l2)\n",
    "\n",
    "def get_regularization_type(regularizer):\n",
    "    if isinstance(regularizer, regularizers.L1):\n",
    "        return \"L1\"\n",
    "    elif isinstance(regularizer, regularizers.L2):\n",
    "        return \"L2\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "regularization_type = get_regularization_type(l2_reg)\n",
    "lambda_value = lambda_l2\n",
    "\n",
    "#Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,  # Minimum change in the monitored quantity to qualify as an improvement.\n",
    "    patience=10,  # Number of epochs with no improvement after which training will be stopped.\n",
    "    verbose=0,  # Verbosity mode.\n",
    "    mode='auto',  # Direction of improvement.\n",
    "    baseline=None,  # Value to reach.\n",
    "    restore_best_weights=False,  # Restore model weights from the epoch with the best value of the monitored quantity.\n",
    "    start_from_epoch=600,  # Epoch from which to start monitoring. This line was missing a comma at its end.\n",
    ")\n",
    "\n",
    "# Building the model\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "key_dim = 64\n",
    "model = build_model(\n",
    "    input_shape, \n",
    "    head_size=256, \n",
    "    num_heads=4, \n",
    "    ff_dim=4, \n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128], \n",
    "    dropout=0.025, \n",
    "    mlp_dropout=0.4)\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(\n",
    "    loss=BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Displaying the model summary\n",
    "model.summary()\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the model checkpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f\"Model_{regularization_type}_{lambda_value}_best.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping, model_checkpoint]  # Include model_checkpoint here\n",
    ")\n",
    "\n",
    "# Get the last epoch\n",
    "last_epoch = len(history.history['loss'])\n",
    "\n",
    "\n",
    "# After training, you can get the training and validation losses like this:\n",
    "train_losses = history.history['loss']\n",
    "val_losses = history.history['val_loss']\n",
    "\n",
    "# Print the final epoch's losses\n",
    "print(f'Epoch {num_epochs}/{num_epochs}, Training Loss: {train_losses[-1]}')\n",
    "print(f'Epoch {num_epochs}/{num_epochs}, Validation Loss: {val_losses[-1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 8ms/step - loss: 32.1108 - accuracy: 0.5213\n",
      "72/72 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "# Storing the true and predicted labels\n",
    "true_labels_test = []\n",
    "predicted_labels_test = []\n",
    "test_losses = []\n",
    "probabilities_list = []\n",
    "\n",
    "# Making predictions\n",
    "y_pred_prob = model.predict(x_test)\n",
    "y_pred = np.where(y_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "# Calculate precision, recall, accuracy and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7526\n",
      "Precision: 0.8253\n",
      "Recall: 0.5213\n",
      "F1 Score: 0.5542\n",
      "Test Accuracy: 0.5213\n",
      "Test Loss: 32.1108\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC and plot ROC curve\n",
    "def sigmoid(scores):\n",
    "    exp_scores = np.exp(-scores)\n",
    "    return 1/ (1 + np.exp(-scores))\n",
    "    #return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "y_pred_prob_softmax = y_pred_prob\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "print(f'AUC: {auc:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Save the ROC plot in the current working directory with the name 'AUC.png'\n",
    "plt.savefig(f'AUC_{regularization_type}_{lambda_value}_{last_epoch}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_evaluation_results__{regularization_type}_{lambda_value}_{last_epoch}.txt', 'w') as file:\n",
    "    file.write(f\"Test Loss = {test_loss:.4f}\\n\")\n",
    "    file.write(f\"Test Accuracy = {test_accuracy:.4f}\\n\")\n",
    "    file.write(f\"Precision = {precision:.4f}\\n\")\n",
    "    file.write(f\"Recall = {recall:.4f}\\n\")\n",
    "    file.write(f\"F1 Score = {f1:.4f}\\n\")\n",
    "    file.write(f\"Overall Accuracy = {overall_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Training vs Validation loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Save the plot in the current working directory with the name plot_1.png\n",
    "plt.savefig('Training vs Validation loss_{regularization_type}_{lambda_value}_{last_epoch}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as Logscale_L1_0.01_3.png\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "x = np.linspace(0.1, 10, 100)\n",
    "y = np.log(x)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "plt.xscale('log')\n",
    "plt.title('Logarithmic scale')\n",
    "plt.xlabel('Logarithmic X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "filename = f\"Logscale_{regularization_type}_{lambda_value}_{last_epoch}.png\"\n",
    "plt.savefig(filename)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plot saved as {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
